{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "<h1><center><font size=\"6\">Honye Bee Subspecies Classification</font></center></h1>\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Bee-apis.jpg/337px-Bee-apis.jpg\"></img>\n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Prepare the data analysis</a>  \n - <a href='#21'>Load packages</a>  \n - <a href='#21'>Load the data</a>  \n - <a href='#21'>Preprocessing data</a>  \n- <a href='#3'>Data exploration</a>   \n - <a href='#31'>Check for missing data</a>  \n - <a href='#32'>Explore image data</a>  \n - <a href='#33'>Location</a>  \n - <a href='#34'>Date and Time</a>  \n - <a href='#35'>Subspecies</a>  \n  - <a href='#36'>Health</a>  \n  - <a href='#37'>Pollen carrying</a>  \n  - <a href='#38'>Caste</a>  \n- <a href='#4'>Subspecies classification</a>  \n - <a href='#40'>Split the data</a>  \n - <a href='#41'>Build a baseline model</a>  \n - <a href='#42'>Model evaluation</a>    \n - <a href='#43'>Add Dropout</a>  \n - <a href='#44'>Model refinement</a>  \n- <a href='#6'>Conclusions</a>    \n- <a href='#7'>References</a>    "
    },
    {
      "metadata": {
        "_uuid": "a8e77ace65f04c89a878bf18249e4d8e23fec996"
      },
      "cell_type": "markdown",
      "source": "# <a id='1'>Introduction</a>  \n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>  "
    },
    {
      "metadata": {
        "_uuid": "4e97555eb77978a29a51c41f39cec67136b18157"
      },
      "cell_type": "markdown",
      "source": "# <a id='2'>Prepare the data analysis</a>   \n\n\nBefore starting the analysis, we need to make few preparation: load the packages, load and inspect the data.\n\n"
    },
    {
      "metadata": {
        "_uuid": "cb2e73fe056a3dda7eb48eeac2facf0c441816d1"
      },
      "cell_type": "markdown",
      "source": "# <a id='21'>Load packages</a>\n\nWe load the packages used for the analysis.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "af08260bfbe163f9132f39d09627899bbc4c1dae",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport sys\nimport os\nimport random\nfrom pathlib import Path\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport scipy\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization,LeakyReLU\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom keras.utils import to_categorical\nimport tensorflow",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "a2082fb1e56fc6cfc91d40820b905267bc1ca468"
      },
      "cell_type": "code",
      "source": "IMAGE_PATH = '../input/bee_imgs/bee_imgs/'\nIMAGE_WIDTH = 100\nIMAGE_HEIGHT = 100\nIMAGE_CHANNELS = 3\nRANDOM_STATE = 2018\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2\nCONV_2D_DIM_1 = 16\nCONV_2D_DIM_2 = 16\nCONV_2D_DIM_3 = 32\nCONV_2D_DIM_4 = 64\nMAX_POOL_DIM = 2\nKERNEL_SIZE = 3\nBATCH_SIZE = 32\nNO_EPOCHS_1 = 5\nNO_EPOCHS_2 = 10\nNO_EPOCHS_3 = 50\nPATIENCE = 5\nVERBOSE = 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "307f656565365ff05faf226e5a447875dd0dfead"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n# <a id='22'>Load the data</a>  \n\nLet's see first what data files do we have in the root directory."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f1df6658b17558179d8a9016f544410de16c354",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "os.listdir(\"../input\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "241b8735a85a25e16421fda8c35bc3d3c69e7ea8"
      },
      "cell_type": "markdown",
      "source": "There is a dataset file and a folder with images.  \n\nLet's load the dataset file first."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d7b9f11a014428e56e422d97a5b3ef70efec007e",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "honey_bee_df=pd.read_csv('../input/bee_data.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "22b3984ccc3e29daaf77a796d9d7966cd798e1a8"
      },
      "cell_type": "markdown",
      "source": "Let's glimpse the data. First, let's check the number of columns and rows."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "535f3f9cea3b26428bec3ede4ed49009bdb91889",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "honey_bee_df.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5b4405ddcce03ee722f05234d508188997817f8d"
      },
      "cell_type": "markdown",
      "source": "There are 5172 rows and 9 columns. Let's look to the data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4d326f747f0a14580b20c2e034e6c3368edcd18b",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "honey_bee_df.sample(100).head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c97047b17cda76e346e444229485ac91ec966423"
      },
      "cell_type": "markdown",
      "source": "The data contains the following values:  \n\n* file - the image file name;  \n* date - the date when the picture was taken;\n* time - the time when the picture was taken;\n* location - the US location, with city, state and country names;  \n* zip code - the ZIP code associated with the location;  \n* subspecies - the subspecies to whom the bee in the current image belongs;  \n* health - this is the health state of the bee in the current image;  \n* pollen_carrying - indicates if the picture shows the bee with pollen attached to the legs;  \n* caste - the bee caste;  \n\nIt is important, before going to create a model, to have a good understanding of the data. We will therefore explore the various features, not only the images."
    },
    {
      "metadata": {
        "_uuid": "55dd26f919decca9d67daec9895a5d9e11f1d28b"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n# <a id='3'>Data exploration</a>  \n\n\n\nLet's start by checking if there are missing data, unlabeled data or data that is inconsistently labeled. \n"
    },
    {
      "metadata": {
        "_uuid": "14443450ba96e12ad8e18ce4dd1779f18d5f914b"
      },
      "cell_type": "markdown",
      "source": "## <a id='31'>Check for missing data</a>  \n\nLet's create a function that check for missing data in the dataset."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4544dd470d743c54f815faaee863038ad5e8398f",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data(honey_bee_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3cb0410e8b9afd75ac7b50d0489d90eda6e1b109"
      },
      "cell_type": "markdown",
      "source": "There is no missing (null) data in the dataset. Still it might be that some of the data labels are misspelled; we will check this when we will analyze each data feature."
    },
    {
      "metadata": {
        "_uuid": "1fbab44688fb2ab073aac8f964e534f90ce1dfff"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='32'>Explore image data</a>  \n\nLet's also check the image data. First, we check how many images are stored in the image folder."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46f15681887fa82ab13224e52df69d91119fc9ad",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "image_files = list(os.listdir(IMAGE_PATH))\nprint(\"Number of image files: {}\".format(len(image_files)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68523860593e9a64059b51d40a316454e6937a68"
      },
      "cell_type": "markdown",
      "source": "Let's also check that each line in the dataset has a corresponding image in the image list."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "457cd17212904bb96f86ec1770cbdbefc5ffb395",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "file_names = list(honey_bee_df['file'])\nprint(\"Matching image names: {}\".format(len(set(file_names).intersection(image_files))))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6253c64c9d971e624772e8be06eb35d913c328de"
      },
      "cell_type": "markdown",
      "source": "We will also load images associated with each features categories, in the following sections."
    },
    {
      "metadata": {
        "_uuid": "a2b88af0c239ca3d9e37e159889836a4f38913c8"
      },
      "cell_type": "markdown",
      "source": "## <a id='33'>Locations</a>  \n\nLet's check the locations of the images. For this, we will group by `location` and `zip code`."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f1c39d0398275215f92f61542544132a0d574a0",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['zip code'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd421a7d1872af204c26588d1a15eaddca08a396"
      },
      "cell_type": "markdown",
      "source": "We observe that `Athens, GA, USA` is actually the same location as `Athens, Georgia, USA`, only written differently (the `zip code` is the same as well). Let's modify the data to have the same location name for both."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57c4f7bac571131392374b462f69cfcd24ec5f79",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "honey_bee_df = honey_bee_df.replace({'location':'Athens, Georgia, USA'}, 'Athens, GA, USA')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fdf585a7e29da16a9043b969e3ca9d2afabae16c",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['zip code'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf['code'] = df['location'].map(lambda x: x.split(',', 2)[1])\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "974c1ba8e721ca1879864b701bdf41bc84e668cc"
      },
      "cell_type": "markdown",
      "source": "Let's visualize now the **location** data."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "b978a0e04e5ef3fa15c99cd9c0e67045af6e8452"
      },
      "cell_type": "code",
      "source": "trace = go.Bar(\n        x = df['location'],\n        y = df['Images'],\n        marker=dict(color=\"Tomato\"),\n        text=df['location']\n    )\ndata = [trace]\n    \nlayout = dict(title = 'Number of bees images per location',\n          xaxis = dict(title = 'Subspecies', showticklabels=True, tickangle=15), \n          yaxis = dict(title = 'Number of images'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-location')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "44620aed21e3412cd95493e8034d95b1095d3700"
      },
      "cell_type": "markdown",
      "source": "Most of the images (2000) were captured in `Saratoga, California`. On second place is `Athens, Georgia` (1051), followed by `Des Moines, Iowa` (973).   \n\nLet's load few images, one per each location."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "b8cf9ce34783bda8b121c67bb81461b75b071fb1"
      },
      "cell_type": "code",
      "source": "#list of locations\nlocations = (honey_bee_df.groupby(['location'])['location'].nunique()).index",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "078d947f264182dee5db0b172b91715ac6c98969",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "def draw_category_images(var,cols=5):\n    categories = (honey_bee_df.groupby([var])[var].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=cols, figsize=(2*cols,2*len(categories)))\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = honey_bee_df[honey_bee_df[var]==cat].sample(cols)\n        for j in range(0,cols):\n            file=IMAGE_PATH + sample.iloc[j]['file']\n            im=imageio.imread(file)\n            ax[i, j].imshow(im, resample=True)\n            ax[i, j].set_title(cat, fontsize=9)  \n    plt.tight_layout()\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9df59a4228f0838c73b67f3e4579041a373b8e4f",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "draw_category_images(\"location\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d9c080eae3157070f2526a140e4becdfcfb7bf23"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='34'>Date and time</a>   \n\nLet's first convert date to datetime and extract year, month and day.  We also convert time and extract hour and minute."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f103bccb829b9c909a251ddf301ba74e1b11713d",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "honey_bee_df['date_time'] = pd.to_datetime(honey_bee_df['date'] + ' ' + honey_bee_df['time'])\nhoney_bee_df[\"year\"] = honey_bee_df['date_time'].dt.year\nhoney_bee_df[\"month\"] = honey_bee_df['date_time'].dt.month\nhoney_bee_df[\"day\"] = honey_bee_df['date_time'].dt.day\nhoney_bee_df[\"hour\"] = honey_bee_df['date_time'].dt.hour\nhoney_bee_df[\"minute\"] = honey_bee_df['date_time'].dt.minute",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f36bdc8d4cf9cf0cb4e917a4951949ad836d5019"
      },
      "cell_type": "markdown",
      "source": "Let's plot the date/time distribution of the data. We group the data on `date_time` and count the images. We will represent the date on x-axis, the time (with hours resolution) on y-axis, and one circle with area proportional with the number of images taken for each location corresponding to the date and hour."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3a4f369c2bb46ae2761f4508188327a2de72571",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['date_time', 'hour'])['location'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\nhover_text = []\nfor index, row in df.iterrows():\n    hover_text.append(('Date/time: {}<br>'+\n                      'Hour: {}<br>'+\n                      'Location: {}<br>'+\n                      'Images: {}').format(row['date_time'],\n                                            row['hour'],\n                                            row['location'],\n                                            row['Images']))\ndf['hover_text'] = hover_text\nlocations = (honey_bee_df.groupby(['location'])['location'].nunique()).index\ndata = []\nfor location in locations:\n    dfL = df[df['location']==location]\n    trace = go.Scatter(\n        x = dfL['date_time'],y = dfL['hour'],\n        name=location,\n        marker=dict(\n            symbol='circle',\n            sizemode='area',\n            sizeref=0.2,\n            size=dfL['Images'],\n            line=dict(\n                width=2\n            ),),\n        mode = \"markers\",\n        text=dfL['hover_text'],\n    )\n    data.append(trace)\n    \nlayout = dict(title = 'Number of bees images per date, approx. hour and location',\n          xaxis = dict(title = 'Date', showticklabels=True), \n          yaxis = dict(title = 'Hour'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\n\niplot(fig, filename='images-date_time')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "987e3a00c68b5b318ebac6663eaef1ac500fab22"
      },
      "cell_type": "markdown",
      "source": "Let's also show now a number of images per each day **hour**."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "8c5af9e5ed8a6d721e54208881d688e192fcef41"
      },
      "cell_type": "code",
      "source": "draw_category_images(\"hour\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "61bc75e33d136a5b63382838bf5766d847c6d01b"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='34'>Subspecies</a>   \n\nLet's plot now the subspecies distribution."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "40e0f13ffb3bcf217954095fb7578ddf35c48973"
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['subspecies'])['year'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "70546715903314d4a4ce253488aff0602dbf89c5"
      },
      "cell_type": "code",
      "source": "trace = go.Bar(\n        x = df['subspecies'],\n        y = df['Images'],\n        marker=dict(color=\"Green\"),\n        text=df['subspecies']\n    )\ndata = [trace]\n    \nlayout = dict(title = 'Number of bees images per subspecies',\n          xaxis = dict(title = 'Subspecies', showticklabels=True, tickangle=15), \n          yaxis = dict(title = 'Number of images'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-subspecies')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2327b89ba2ee56d44b7b2a496d679b71b3ff3b28"
      },
      "cell_type": "markdown",
      "source": "The majority of subspecies are `Italian honey bee`,  with 3008 images, followed by `Russian honey bee` (527) and `Carniolan honey bee` (501). There is a relativelly large number of subspecies not identified, marked with `-1` (428)."
    },
    {
      "metadata": {
        "_uuid": "075e1932fa0321a4c86ef839cf85dac4a50ef79a"
      },
      "cell_type": "markdown",
      "source": "Let's show few images of each **subspecies**."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "2604b66b64099487ad2aeabecfcd2b129bafa1e7"
      },
      "cell_type": "code",
      "source": "draw_category_images(\"subspecies\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "07479c4b334dd003ab27ce73c8bd7225e69d7830"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='35'>Health</a>   \n\nLet's plot now the health distribution."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "3e42de343a40852ec54356682ae95de15c351ff8"
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['health'])['year'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "2883d13b37f33f4a4c00bee03cbd78570d7267ae"
      },
      "cell_type": "code",
      "source": "trace = go.Bar(\n        x = df['health'],\n        y = df['Images'],\n        marker=dict(color=\"Red\"),\n        text=df['health']\n    )\ndata = [trace]\n    \nlayout = dict(title = 'Number of bees images per health',\n          xaxis = dict(title = 'Health', showticklabels=True, tickangle=15), \n          yaxis = dict(title = 'Number of images'),\n          hovermode = 'closest'\n         )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-health')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "52ca32ede63b574d5963e2f18d803caab1c690bd"
      },
      "cell_type": "markdown",
      "source": "Majority of images are for healthy bees (3384), followed by `feq varrao, hive beetles` (579) and `Varroa, Small Hive Beetles` (472) and `ant problems` (457)."
    },
    {
      "metadata": {
        "_uuid": "fb5e9297c114944fefaafa56a6ab211c4dff3df8"
      },
      "cell_type": "markdown",
      "source": "Let's plot on the same graph subspecies and health."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "af3dcc128760e91e1a2f761cdbf03e8df8ac854c"
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['subspecies'])['health'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c80ab3a07989d44cc78a03ee66f9eb95e94566d0",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "piv = pd.pivot_table(df, values=\"Images\",index=[\"subspecies\"], columns=[\"health\"], fill_value=0)\nm = piv.values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "1f6e0f190b2a4c326ff37f0b762c29fd3f547dc6"
      },
      "cell_type": "code",
      "source": "trace = go.Heatmap(z = m, y= list(piv.index), x=list(piv.columns),colorscale='Rainbow',reversescale=False)\n    \ndata=[trace]\nlayout = dict(title = \"Number of images per subspecies and health\",\n              xaxis = dict(title = 'Subspecies',\n                        showticklabels=True,\n                           tickangle = 45,\n                        tickfont=dict(\n                                size=10,\n                                color='black'),\n                          ),\n              yaxis = dict(title = 'Health', \n                        showticklabels=True, \n                           tickangle = 45,\n                        tickfont=dict(\n                            size=10,\n                            color='black'),\n                      ), \n              hovermode = 'closest',\n              showlegend=False,\n                  width=600,\n                  height=600,\n             )\nfig = dict(data = data, layout = layout)\niplot(fig, filename='images-health_subspecies')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4af46caf797b70aaab2728bacb710dc0bedf6d82"
      },
      "cell_type": "markdown",
      "source": "Only a reduced number of combination of health and subspecies values are present. The majority of images are of `healthy` `Italian honey bee` (1972), followed by `few varrao, hive beetles`  `Italian honey bee` (579) and  `healthy` `Russian honey bee` (527). The unknown subspecies are either `healthy` (177) or `hive being robbed` (251). \n\nLet's plot few images for each **health** category."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "5a55bf50eee2c193284a6d1cf83605eabf92687f"
      },
      "cell_type": "code",
      "source": "draw_category_images(\"health\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "995b4083742a1371787e1c614ee843ea52225795"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='36'>Pollen carying</a>   \n\nLet's check now the pollen carying distribution."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "ad7da88a35c5fc6872d80e7dd676163fc5e66d2b"
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['pollen_carrying'])['year'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "79694b1ccb952b53062d99fc49fae1d93ec1dbd8"
      },
      "cell_type": "markdown",
      "source": "Only 18 out of 5172 (0.34%) of the images are of bees carrying pollen. We will not try to predict this, as the data is highly unballanced. Let's see what species have pollen carrying."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "e52e1625e7602fd1ad352a820e23097971f8cdd7"
      },
      "cell_type": "code",
      "source": "tmp = honey_bee_df.groupby(['pollen_carrying'])['subspecies'].value_counts()\ndf = pd.DataFrame(data={'Images': tmp.values}, index=tmp.index).reset_index()\ndf[df['pollen_carrying']==True]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72f2130a17b81ee39e604d0b93aafd8a0990f37f"
      },
      "cell_type": "markdown",
      "source": "Majority of pollen carrying bees are of unknown species (67%) and the rest (33%) are `Italian honey bee`.  \n\nLet's plot few images with honey bees either **carrying pollen** or not."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "5899b06541c1888b2918cd1963663441c81d001a"
      },
      "cell_type": "code",
      "source": "draw_category_images(\"pollen_carrying\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "037c7be0ed553383d169d4465459a84e60b2ff6b"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='37'>Caste</a>   \n\nLet's check now the`Caste` distribution."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "866a725b3f3ed7f9815cf9ee442eb18b172a44e6"
      },
      "cell_type": "code",
      "source": "honey_bee_df.groupby(['caste'])['caste'].nunique()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d3cbdebbc697f1ff8161fb38eb4bf1d640619af0"
      },
      "cell_type": "markdown",
      "source": "All the bees are of `worker` caste.   \n\n\n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>  "
    },
    {
      "metadata": {
        "_uuid": "c2a5e2401b418f1723c859ee9e0b4ad5071e4a82"
      },
      "cell_type": "markdown",
      "source": "# <a id='4'>Subspecies classification</a>\n\nOur objective is to use the images that we investigated until now to correctly identify the subspecies. We have a unique dataset and we will have to split this dataset in **train** and **test**. The **train** set will be used for training a model and the test will be used for testing the model accuracy against new, fresh data, not used in training.\n\n"
    },
    {
      "metadata": {
        "_uuid": "e8c0a6df4bb85bcdf90f7c908decab07304d660f"
      },
      "cell_type": "markdown",
      "source": "## <a id='40'>Split the data</a>  \n\nFirst, we split the whole dataset in train and test. We will use **random_state** to ensure reproductibility of results.   \n\nThe train-test split is **90%** for training set and **10%** for test set.\n"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "352d452d5212d8c9eff074f11820b03a0d44387b"
      },
      "cell_type": "code",
      "source": "train_df, test_df = train_test_split(honey_bee_df, test_size=TEST_SIZE, random_state=RANDOM_STATE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "856060cc500db00e472b7755c91aba20c953a5f6"
      },
      "cell_type": "markdown",
      "source": "Next, we will split further the **train** set in **train** and **validation**. We want to use as well a validation set to be able to measure not only how well fits the model the train data during training (or how well `learns` the training data) but also how well the model is able to generalize so that we are able to understands not only the bias but also the variance of the model.  \n\nThe train-validation split is **90%** for training set and **10%** for validation set."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "83d0be04ae5a4ad5834631bf18e21917d6313bcd"
      },
      "cell_type": "code",
      "source": "train_df, val_df = train_test_split(train_df, test_size=VAL_SIZE, random_state=RANDOM_STATE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "0dcaa8c2c5423ab8fc2898d4a4aa937801592c2c"
      },
      "cell_type": "markdown",
      "source": "Let's check the shape of the three datasets."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8247f70b4deb4600fe322f004733234ed37617f0",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "print(\"Train set rows: {}\".format(train_df.shape[0]))\nprint(\"Test  set rows: {}\".format(test_df.shape[0]))\nprint(\"Val   set rows: {}\".format(val_df.shape[0]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee768c083f40fcbd109425182bc55ce86173b69d"
      },
      "cell_type": "markdown",
      "source": "We are now ready to start building our first model."
    },
    {
      "metadata": {
        "_uuid": "d76e822dd76565d29fcfed323cb034939f307581"
      },
      "cell_type": "markdown",
      "source": "## <a id='41'>Build a baseline model</a>    \n\n\nNext step in our creation of a predictive model is to create a simple model, a **baseline model**.  \n\n Why start with a simple model (as simple as possible, but not simpler :-) )?\n \n With a simple model, we can get fast insight in how well will the data predict our target value. Looking to the training results (the training error and accuracy, the validation error and accuracy), we can understand if we need to add more data (because the training accuracy is small) or if we need to optimize the model (by adding more convolutional layers) or if we need to add Dropout layers (because the validation error is increasing after few steps - the model is overfitting) etc.\n \nLet's define few auxiliary functions that we will need for creation of our models.\n\nA function for reading images from the image files, scale all images to 100 x 100 x 3 (channels)."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "f80b4e20e98ce5bf328fba3a22457c4a994de06b"
      },
      "cell_type": "code",
      "source": "def read_image(file_name):\n    image = skimage.io.imread(IMAGE_PATH + file_name)\n    image = skimage.transform.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT), mode='reflect')\n    return image[:,:,:IMAGE_CHANNELS]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e396e0cd23633af2169e4d50985f1987654205a9"
      },
      "cell_type": "markdown",
      "source": "A function to create the dummy variables corresponding to the categorical target variable."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "0f7a2146ca93aef9367ecd64300980005d89911b"
      },
      "cell_type": "code",
      "source": "def categories_encoder(dataset, var='subspecies'):\n    X = np.stack(dataset['file'].apply(read_image))\n    y = pd.get_dummies(dataset[var], drop_first=False)\n    return X, y",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "b40c205d5189b23cbbc4ef0cda8798721d504ff9"
      },
      "cell_type": "markdown",
      "source": "Let's populate now the train, val and test sets with the image data and create the  dummy variables corresponding to the categorical target variable, in our case `subspecies`."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "70acefcd6dc5d494b1c7db6dc90bae5f8c856d94"
      },
      "cell_type": "code",
      "source": "X_train, y_train = categories_encoder(train_df)\nX_val, y_val = categories_encoder(val_df)\nX_test, y_test = categories_encoder(test_df)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5093354dc9c7f0510ba54a254690db45e38d0bcc"
      },
      "cell_type": "markdown",
      "source": "Now we are ready to start creating our model.  \n\nWe will add the folllowing elements to our model: \n* One convolutional layer, with 16 filters of dimmension 3;  \n* One maxpoll2d layer, with reduction factor 2;  \n* One convolutional layer, with 16 filters of dimmension 3;  \n* A flatten layer;  \n* A dense layer;  "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd7147baf9c45217988df92cf631202684fb3609",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "model1=Sequential()\nmodel1.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel1.add(MaxPool2D(MAX_POOL_DIM))\nmodel1.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\nmodel1.add(Flatten())\nmodel1.add(Dense(y_train.columns.size, activation='softmax'))\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "046612eda2408801ded03cc6a5e2357a99298969",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "model1.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "725cef4194ab0eeb3901ba68f5226aa94ccda331"
      },
      "cell_type": "markdown",
      "source": "We are also using a **ImageDataGenerator** that creates random variation of the training dataset, by applying various techniques, including:\n* rotation (in a range of 0-180 degrees) of the original images;  \n- zoom (10%);  \n- shift in horizontal and in vertical direction (10%);  \n- horizontal and vertical flip;  \n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2e402a92832cfd95cb3668431482d40854bb93a",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "image_generator = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=180,\n        zoom_range = 0.1, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True,\n        vertical_flip=True)\nimage_generator.fit(X_train)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0149020f748dc9eaa89ebf732829031d6d9d35a2"
      },
      "cell_type": "markdown",
      "source": "We train the first model using **fit_generator** and a predefined batch size. The **steps_per_epoch** is calculated to be size of the training set divided by the batch size. We are using the predefined epoch number for this first experiment (5 steps) and as well validation, using the validation set. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19ac76b9eed3495049a0546402368a529c5db2cb",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "train_model1  = model1.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                        epochs=NO_EPOCHS_1,\n                        validation_data=[X_val, y_val],\n                        steps_per_epoch=len(X_train)/BATCH_SIZE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5837b3e9cb131fab2c58f4b9de92f147f48b59ae"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n## <a id='42'>Model evaluation</a> \n\n\nLet's start by plotting the loss error for the train and validation set. \nWe define a function to visualize these values."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a87e3beea44a87a806893b798a38d26904d10718",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "def create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(train_model):\n    hist = train_model.history\n    acc = hist['acc']\n    val_acc = hist['val_acc']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    \n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n   \n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n\n    \n    iplot(fig, filename='accuracy-loss')\n\nplot_accuracy_and_loss(train_model1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a77c0127288f090233e70831e6b909c1618efa35"
      },
      "cell_type": "markdown",
      "source": "\nLet's continue by evaluating the **test** set **loss** and **accuracy**. We will use here the test set."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "1f54e33fcba0e3054d364f35a22f69ef350e8e0d"
      },
      "cell_type": "code",
      "source": "score = model1.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "46cd7e86e92ac2ec484f0c38c451465cc16a2736"
      },
      "cell_type": "markdown",
      "source": "Let's check also the test accuracy per class."
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "55e96cfdaf488df5bc3d5511fa062563926227ad"
      },
      "cell_type": "code",
      "source": "def test_accuracy_report(model):\n    predicted = model.predict(X_test)\n    test_predicted = np.argmax(predicted, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68c06c36ae2f89e070c878bf5f660e765d23878b",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "test_accuracy_report(model1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "28293f20eb559420e61e052397bd998fe6e6ff05"
      },
      "cell_type": "markdown",
      "source": "We used a simple model. We separated 20% of the data for testing. From the training data, 80% is used for actual training and 20% for testing.   \nThe data is unbalanced with respect of the classes of subspecies.   \nThe accuracy of the training set obtained after only 5 epochs was 0.86, with a loss of 0.3.    \nThe accuracy of the validation set remained around 0.89 and the loss increased to 0.27 after 3rd epoch.  \n\nAdding additional data will only slightly increase the accuracy of the training set (it is already very good).   \nTo reduce the loss of the validation set (which is a sign of overfitting), we can have three strategies:  \n* add Dropout layers;  \n* introduce strides;  \n* modify the learning rate during the training;  \n"
    },
    {
      "metadata": {
        "_uuid": "74de02a417db465b77495147c810911d81f491a9"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n\n## <a id='43'>Add Dropout</a>  \n\nWe add two Dropout layers.  The role of the Dropout layers is to reduce the overfitting, by dropping, each training epoch, a certain percent of the nodes connections (by rotation). This is equivalent of using less training data and in the same time training the network with various data as well as using `parallel` alternative networks, thus reducing the likelihood that the network will overfit the train data.  \n\nThe definition of the second model is:"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "ca30aceff3500c10383761962a7908f0b2b558f3"
      },
      "cell_type": "code",
      "source": "model2=Sequential()\nmodel2.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel2.add(MaxPool2D(MAX_POOL_DIM))\n# Add dropouts to the model\nmodel2.add(Dropout(0.4))\nmodel2.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n# Add dropouts to the model\nmodel2.add(Dropout(0.4))\nmodel2.add(Flatten())\nmodel2.add(Dense(y_train.columns.size, activation='softmax'))\nmodel2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cff8a87a7e837de5dd0b001ace6249933027d95b"
      },
      "cell_type": "markdown",
      "source": "Let's inspect the new model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "63dff8b355758d2d55d3e7aff154e9ed6f23d961",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "model2.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd8b5497fa489c35d7ff77319f7d05de46186ac1"
      },
      "cell_type": "markdown",
      "source": "We can observe that this model has the same number of parameters and trainable parameters as  the previous model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b97e8d966f8a369c4503bffd419d57c1d113bd1b",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "train_model2  = model2.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                        epochs=NO_EPOCHS_2,\n                        validation_data=[X_val, y_val],\n                        steps_per_epoch=len(X_train)/BATCH_SIZE)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2254e9082c703f5744f61bc59018f107aca6757c"
      },
      "cell_type": "markdown",
      "source": "### Evaluate model accuracy and loss"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9a69aeb83cee0c57a2e362349925ff509c7af7ee",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "plot_accuracy_and_loss(train_model2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dc0fb043121e04f92f1af7d7821b8581cca8c572"
      },
      "cell_type": "markdown",
      "source": "### Test accuracy and loss\n\nLet's evaluare as well the test accuracy and loss."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19285aa59a4a6dabbf55e81ebdc235ef50c46411",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "test_accuracy_report(model2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "349c34acbba6d761b959a0a7a5b31df9abdf722b"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n## <a id='45'>Model refinement</a>  \n\n\nWe define now also a refined model. \n\nWe add an early stopping condition (monitor the loss error and stops the training if for a number of stept given in the `patience` parameters the loss is not improving).\n\nWe are also saving a model checkpoint after each epoch when accuracy improves; if accuracy degrades, no new model is saved. Thus, Model Checkpoint saves all the time the best model in terms of accuracy.  \n\nWe adjust as well the learning rate with the training epochs.\n\nAlso, we increase the number of training epochs to 50.\n\n"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "deb1e2d4ced60d163ae5257830a3b60dc2d8fc0f"
      },
      "cell_type": "code",
      "source": "annealer3 = LearningRateScheduler(lambda x: 1e-3 * 0.995 ** (x+NO_EPOCHS_3))\nearlystopper3 = EarlyStopping(monitor='loss', patience=PATIENCE, verbose=VERBOSE)\ncheckpointer3 = ModelCheckpoint('best_model_3.h5',\n                                monitor='val_acc',\n                                verbose=VERBOSE,\n                                save_best_only=True,\n                                save_weights_only=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83da1405441c237be0537abd81baf8f90638ce40",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "model3=Sequential()\nmodel3.add(Conv2D(CONV_2D_DIM_1, kernel_size=KERNEL_SIZE, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT,IMAGE_CHANNELS), activation='relu', padding='same'))\nmodel3.add(MaxPool2D(MAX_POOL_DIM))\n# Add dropouts to the model\nmodel3.add(Dropout(0.4))\nmodel3.add(Conv2D(CONV_2D_DIM_2, kernel_size=KERNEL_SIZE, activation='relu', padding='same'))\n# Add dropouts to the model\nmodel3.add(Dropout(0.4))\nmodel3.add(Flatten())\nmodel3.add(Dense(y_train.columns.size, activation='softmax'))\nmodel3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "66c5f7c6d62ee01b17b85960456f7b0502415aa8"
      },
      "cell_type": "markdown",
      "source": "Let's inspect the refined model."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b521fad3c6db559e77eeee1147f0b7a02fd91a13",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "model3.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_uuid": "c773e443457fb4999513b5d0eb7d2454bae419e7"
      },
      "cell_type": "markdown",
      "source": "Now, let's train the model."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "a7ac74a25bed9338906effff9d7df171d7b8b154",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "train_model3  = model3.fit_generator(image_generator.flow(X_train, y_train, batch_size=BATCH_SIZE),\n                        epochs=NO_EPOCHS_3,\n                        validation_data=[X_val, y_val],\n                        steps_per_epoch=len(X_train)/BATCH_SIZE,\n                        callbacks=[earlystopper3, checkpointer3, annealer3])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c1d333286edff47c2452cdd54df91c5ad7959ef7"
      },
      "cell_type": "markdown",
      "source": "### Model accuracy and loss"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8adfacee0f01e584915a712f0501c105287e70dc",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "plot_accuracy_and_loss(train_model3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c0a45ee7288e16e571110dd134248ec880ccaadc"
      },
      "cell_type": "markdown",
      "source": "### Test accuracy and loss"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ad166de21bdd7e097fb73e64ec564b61358a6c1",
        "_kg_hide-input": true
      },
      "cell_type": "code",
      "source": "test_accuracy_report(model3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cd6bd3fba3f98e9775dac4f313371af4701febf3"
      },
      "cell_type": "markdown",
      "source": "<a href=\"#0\"><font size=\"1\">Go to top</font></a>  \n\n# <a id='6'>Conclusions</a>  \n\nAfter exploring the data to understand its various features, a baseline model is created.   \nEvaluation of the baseline model  results for valid set and test set allows us to conclude that, while the bias is small (training accuracy is big, training loss is small), the variance is large (validation loss is large and increases after 3rd epoch, as well as validation accuracy is smaller than train accuracy and stop increasing after 3rd epoch); this means we are overfitting.  The accurary of the test set obtained with the baseline model was 0.88.\n\nFrom the possible solutions for overfitting, we choose to add Dropout layers. Adding Dropout layers improve a bit the algorithm performance (reduce overfitting). Implementing an image augmentation technique help as well to improve performance, in two ways: increase the data dimmension (which can improve the accuracy) and make more robust the training.   Accuracy of the test set obtained after adding Dropout was ~0.92.\n\nA third model, with adjustable learning rate, early stoping based on validation accuracy measurement and saving the model with best accuracy was also created. With this model, accuracy of prediction for the test set improved to an average ~0.94.\n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# <a id='7'>References</a>  \n\n[1] Gabriel Preda, RSNA Pneumonia Detection EDA, https://www.kaggle.com/gpreda/rsna-pneumonia-detection-eda     \n[2] Gabriel Preda, CNN with Tensorflow|Keras for Fashion-MNIST, https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion-mnist    \n[3] DanB, CollinMoris, Deep Learning From Scratch, https://www.kaggle.com/dansbecker/deep-learning-from-scratch  \n[4] DanB, Dropout and Strides for Larger Models, https://www.kaggle.com/dansbecker/dropout-and-strides-for-larger-models  \n[5] BGO, CNN with Keras, https://www.kaggle.com/bugraokcu/cnn-with-keras  \n[6] Dmitri Pukhov, Hony Bee health detection using CNN, https://www.kaggle.com/gpreda/honey-bee-health-detection-with-cnn/notebook     \n[7] Why Dropounts prevent overfitting in Deep Neural Networks, https://medium.com/@vivek.yadav/why-dropouts-prevent-overfitting-in-deep-neural-networks-937e2543a701  \n[8] Dropout: A Simple Way to Prevent Neural Networks from Overfitting, https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf  \n\n<a href=\"#0\"><font size=\"1\">Go to top</font></a>\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}